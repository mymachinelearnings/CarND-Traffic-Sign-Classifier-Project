{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'sizes', 'coords', 'features'])\n",
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2ab944dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before Shuffling [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41]\n",
      "Laels after Shuffling [ 9 23  2 10  9 15 19 17 34 11 10 41 26 14 25 10 22  1  8  4 21 10 12 25 31]\n",
      "9\n",
      "printing done!!!\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Load pickled data\n",
    "# Pickle is used to serialize the data so that it can be saved to a disk\n",
    "\n",
    "training_file = './data/train.p'\n",
    "validation_file = './data/valid.p'\n",
    "testing_file = './data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "#Each pickled dataset is a dictionary of 4 keys\n",
    "#dict_keys(['sizes', 'labels', 'features', 'coords'])\n",
    "print(train.keys())\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "LEARN_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 8\n",
    "\n",
    "#Number of labels should be same as number of input images\n",
    "assert(len(X_train) == len(y_train))\n",
    "n_train = len(X_train)\n",
    "\n",
    "assert(len(X_valid) == len(y_valid))\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "assert(len(X_test) == len(y_test))\n",
    "n_test = len(X_test)\n",
    "\n",
    "# Image Shape\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# Number of classes / labels\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "def readcsv(file):\n",
    "    with open(file) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        label_dict = {row['ClassId']:row['SignName'] for row in reader}\n",
    "        return label_dict\n",
    "\n",
    "# Visualizations will be shown in the notebook using this command\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[random.randint(0, n_train)])\n",
    "plt.show()\n",
    "\n",
    "#Number of occurances of types of images in training set\n",
    "count, label = np.unique(y_train, return_counts=True)\n",
    "label_dict = readcsv('signnames.csv')\n",
    "# for i, j in zip(count, label):\n",
    "#     print('{} :: {}'.format(label_dict[repr(i)], j))\n",
    "\n",
    "def get_label_name(label_no):\n",
    "    return label_dict[label_no]\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "#Images are in order, so shuffle them\n",
    "print('Labels before Shuffling', y_train[:25])\n",
    "\n",
    "X_train_shuffle, y_train_shuffle = shuffle(X_train, y_train)\n",
    "print('Laels after Shuffling', y_train_shuffle[:25])\n",
    "\n",
    "#To check if the count has changed after shuffling, which ideally shouldn't\n",
    "label, count = np.unique(y_train_shuffle, return_counts=True)\n",
    "#print('count',count)\n",
    "label_dict_shuffle = readcsv('signnames.csv')\n",
    "#print('\\nLabels vs Count to ensure this pair doesn\\'t change post shuffling\\n')\n",
    "count_var = []\n",
    "for i, j in zip(count, label):\n",
    "    #print('{} :: {}'.format(label_dict_shuffle[repr(j)], i))\n",
    "    count_var.append(i)\n",
    "\n",
    "plt.plot(count_var)\n",
    "plt.title('Distribution of Labels vs number of images')\n",
    "\n",
    "    \n",
    "\n",
    "####################################################################################################################\n",
    "# PRE PROCESSING DATA - SHUFFLE, NORMALIZATION\n",
    "X_train_shuffle_normalized = (X_train_shuffle - 127.5) / 255\n",
    "\n",
    "#No change in shape due to normalization\n",
    "#print('Orignal Shape of the Image {} \\nShape after normalization {}'.format(X_train[0].shape, \\\n",
    "#                                                                            X_train_shuffle_normalized[0].shape))\n",
    "\n",
    "#Mean value after normalization\n",
    "#X_train_shuffle_mean = np.mean(X_train_shuffle_normalized)\n",
    "\n",
    "#print('Original Mean {} \\nNormalized Mean {}'.format(np.mean(X_train_shuffle), X_train_shuffle_mean))\n",
    "\n",
    "#TODO - Loop through and display 10 images\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     plt.figure(3)\n",
    "#     plt.subplot(5,2,i+1)\n",
    "#     img_name = get_label_name(repr(y_train_shuffle[i]))\n",
    "#     plt.title(img_name)\n",
    "#     plt.imshow(X_train_shuffle_normalized[i])\n",
    "\n",
    "#Assigning back to original input variables after pre-processing\n",
    "X_train, y_train = X_train_shuffle_normalized, y_train_shuffle\n",
    "\n",
    "#This is to ensure the data is correct after shuffling\n",
    "plt.figure(4)\n",
    "plt.subplot(221)\n",
    "print(y_train[0])\n",
    "name = get_label_name(repr(y_train[0]))\n",
    "plt.title(name)\n",
    "plt.imshow(X_train[0])\n",
    "plt.subplot(222)\n",
    "plt.title(name)\n",
    "plt.imshow(X_train_shuffle[0])\n",
    "print('printing done!!!')\n",
    "\n",
    "####################################################################################################################\n",
    "# Conv --> MaxPool --> Conv --> MaxPool --> FC1 --> FC2 --> o/p\n",
    "def NN_LeNet(inputs):\n",
    "    \"\"\"\n",
    "    LeNet Architecture\n",
    "    CN1 --> P1 --> CN2 --> P2 --> Flatten --> FC1 --> FC2 --> O/P\n",
    "    Each step after CN & FC follows by an activation layer\n",
    "    Here are the dimensions of LeNet\n",
    "\n",
    "    Input : 32, 32, 3 #3 channels for RGB. If you are using Gray scale, then have this as 1\n",
    "    Layer1 : CN1 Output : 28, 28, 6\n",
    "    Layer2 : P1 Output  : 14, 14, 6\n",
    "    Layer3 : CN2 Output : 10, 10, 16\n",
    "    Layer4 : P2 Output  : 5, 5, 16\n",
    "    Layer5 : FC1 Output : 120\n",
    "    Layer6 : FC2 Output : 84\n",
    "    Layer7 : Logits     : 43 #43 different classes in German Traffic Sign dataset\n",
    "    \"\"\"\n",
    "\n",
    "    #Defining weights, bias and outputs for each Layer\n",
    "    mu = 0 #Mean of the variables in the random distribution\n",
    "    sigma = 0.1 #Variance is 0.1\n",
    "    \n",
    "    #Layer1 - Convolution - Output Size : 28, 28, 6\n",
    "    w_layer1 = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean=mu, stddev=sigma))\n",
    "    b_layer1 = tf.Variable(tf.zeros(6))\n",
    "    conv_layer1 = tf.nn.conv2d(inputs, w_layer1, strides=[1,1,1,1], padding='VALID') + b_layer1\n",
    "    act_layer1 = tf.nn.relu(conv_layer1)\n",
    "\n",
    "    #Layer2 - Max Pooling - Output Size : 14, 14, 6\n",
    "    pool_layer2 = tf.nn.max_pool(act_layer1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #Layer3 - Convolution - Output Size : 10, 10, 16 ==> 16 filters, size is (W + 2P - F)/S + 1\n",
    "    w_layer3 = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n",
    "    b_layer3 = tf.Variable(tf.zeros(16))\n",
    "    conv_layer3 = tf.nn.conv2d(pool_layer2, w_layer3, strides=[1, 1, 1, 1], padding='VALID') + b_layer3\n",
    "    act_layer3 = tf.nn.relu(conv_layer3)\n",
    "\n",
    "    #Layer4 - Max Pooling - Output Size : 5, 5, 16\n",
    "    pool_layer4 = tf.nn.max_pool(act_layer3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #Flatenning as next layers are fully connected\n",
    "    flatten_vect = tf.contrib.layers.flatten(pool_layer4)\n",
    "\n",
    "    #Layer5 - Fully Connected - Output = 120. Input dimension would be 5*5*16 = 400\n",
    "    w_layer5 = tf.Variable(tf.random_normal(shape=(400, 120), mean=mu, stddev=sigma))\n",
    "    b_layer5 = tf.Variable(tf.zeros(120))\n",
    "    fc_layer5 = tf.matmul(flatten_vect, w_layer5) + b_layer5\n",
    "    act_layer5 = tf.nn.relu(fc_layer5)\n",
    "\n",
    "    #Layer6 - Fully Connected - Output = 84. Input dimension is 120\n",
    "    w_layer6 = tf.Variable(tf.random_normal(shape=(120, 84), mean=mu, stddev=sigma))\n",
    "    b_layer6 = tf.Variable(tf.zeros(84))\n",
    "    fc_layer6 = tf.matmul(act_layer5, w_layer6) + b_layer6\n",
    "    act_layer6 = tf.nn.relu(fc_layer6)\n",
    "\n",
    "    #Layer7 - Logits - Output Size : 43 types of image classes in the input dataset\n",
    "    w_layer7 = tf.Variable(tf.random_normal(shape=(84, 43), mean=mu, stddev=sigma))\n",
    "    b_layer7 = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(act_layer6, w_layer7) + b_layer7\n",
    "    \n",
    "    return logits\n",
    "\n",
    "####################################################################################################################\n",
    "#None is a placeholder which depends on the number of input images in the batch (k)\n",
    "#Observe that input data will be float, but labels will always be integers. Otherwise one hot doesn't work\n",
    "input_data = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "input_labels = tf.placeholder(tf.int32, (None))\n",
    "one_hot_labels = tf.one_hot(input_labels, 43)\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "logits = NN_LeNet(input_data)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_labels)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARN_RATE)\n",
    "training_operation = optimizer.minimize(loss)\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(x_data, y_data):\n",
    "    total_accuracy = 0\n",
    "    length_inputs = len(x_data)\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, length_inputs, BATCH_SIZE):\n",
    "        batch_x, batch_y = x_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        batch_accuracy = sess.run(accuracy, feed_dict={input_data:batch_x, input_labels:batch_y})\n",
    "        total_accuracy += (batch_accuracy * len(batch_x))\n",
    "    return total_accuracy / length_inputs\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_total = len(X_train)\n",
    "    validation_accuracy_plot = []\n",
    "    print('Training...')\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_total, BATCH_SIZE):\n",
    "            batch_x, batch_y = X_train[offset:offset+BATCH_SIZE], y_train[offset:offset+BATCH_SIZE]\n",
    "            sess.run(training_operation, feed_dict={input_data:batch_x, input_labels:batch_y})\n",
    "        \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print('EPOCH {} --- '.format(i+1))\n",
    "        print('Validation Accuracy = {:.3f}'.format(validation_accuracy),'\\n')\n",
    "        validation_accuracy_plot.append(validation_accuracy)\n",
    "        \n",
    "        try:\n",
    "            saver\n",
    "        except NameError:\n",
    "            saver = tf.train.Saver()\n",
    "        saver.save(sess, 'lenet')\n",
    "        print('Model Saved')\n",
    "        \n",
    "        plt.figure(3)\n",
    "        plt.plot(validation_accuracy_plot)\n",
    "        plt.title('Validation Accuracy vs EPOCHS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
